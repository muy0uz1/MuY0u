# --- åŸºç¡€ä¾èµ–å¯¼å…¥ ---
import numpy as np

np.float = float  # å…¼å®¹ByteTrack
import sys, os, cv2, torch, math
from ultralytics import YOLO
from collections import deque, defaultdict
from types import SimpleNamespace
from PIL import Image, ImageDraw, ImageFont

# --- æ¨¡å—è·¯å¾„è®¾ç½® ---
sys.path.append(os.path.join(os.path.dirname(__file__), 'Licensee', 'LPRNet', 'model'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'Licensee', 'MTCNN'))
from LPRNET import LPRNet, CHARS
from STN import STNet
from MTCNN import create_mtcnn_net
from yolox.tracker.byte_tracker import BYTETracker
from Licensee.LPRNet.Evaluation import decode


# ================= é…ç½®ä¼˜åŒ– =================
class Config:
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    VIDEO_PATH = r"D:\studay\CV6\Visual Object Tracking\Traffic\cut.mkv"

    # æ¨¡å‹è·¯å¾„
    YOLO_WEIGHT = "yolov8n.pt"
    LPRNET_WEIGHT = os.path.join("Licensee", "LPRNet", "weights", "Final_LPRNet_model.pth")
    STN_WEIGHT = os.path.join("Licensee", "LPRNet", "weights", "Final_STN_model.pth")
    MTCNN_PNET = os.path.join("Licensee", "MTCNN", "weights", "pnet_Weights")
    MTCNN_ONET = os.path.join("Licensee", "MTCNN", "weights", "onet_Weights")

    # è½¦ç‰Œè¯†åˆ«å¢å¼ºå‚æ•°
    PLATE_MIN_CONF = 0.7  # è½¦ç‰Œæ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼
    PLATE_RECOG_THRESH = 0.6  # è½¦ç‰Œè¯†åˆ«ç½®ä¿¡åº¦é˜ˆå€¼
    PLATE_MIN_AREA = 800  # æœ€å°è½¦ç‰Œé¢ç§¯ï¼ˆè¿‡æ»¤å°ç›®æ ‡ï¼‰
    PLATE_ASPECT_RATIO = (2.5, 5.0)  # è½¦ç‰Œå®½é«˜æ¯”èŒƒå›´ï¼ˆæ ‡å‡†è½¦ç‰Œçº¦3.1-4.0ï¼‰
    PLATE_RECOG_REPEAT = 3  # é‡å¤è¯†åˆ«æ¬¡æ•°ï¼ˆå–å¤šæ•°ç»“æœï¼‰
    PLATE_HISTORY_LEN = 5  # è½¦ç‰Œå†å²ç¼“å­˜é•¿åº¦ï¼ˆç”¨äºæŠ•ç¥¨ï¼‰

    # å…¶ä»–å‚æ•°
    PIXEL_PER_METER = 80
    FRAME_RATE = 30
    SPEED_SMOOTH_WINDOW = 5


# ================= è½¦ç‰Œé¢„å¤„ç†å¢å¼º =================
def preprocess_plate_image(plate_img):
    """
    è½¦ç‰Œå›¾åƒé¢„å¤„ç†ï¼šå¢å¼ºå¯¹æ¯”åº¦ã€å»å™ªã€å­—ç¬¦é”åŒ–
    """
    if plate_img.size == 0:
        return None

    # 1. è½¬æ¢ä¸ºç°åº¦å›¾
    gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)

    # 2. è‡ªé€‚åº”é˜ˆå€¼äºŒå€¼åŒ–ï¼ˆå¢å¼ºå­—ç¬¦ä¸èƒŒæ™¯å¯¹æ¯”ï¼‰
    binary = cv2.adaptiveThreshold(
        gray, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY_INV,
        11, 2
    )

    # 3. å»é™¤å™ªå£°ï¼ˆä¿ç•™å­—ç¬¦ç»†èŠ‚ï¼‰
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))
    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)

    # 4. è¾¹ç¼˜å¢å¼ºï¼ˆçªå‡ºå­—ç¬¦è½®å»“ï¼‰
    edges = cv2.Canny(binary, 50, 150)
    edges = cv2.dilate(edges, kernel, iterations=1)

    # 5. åˆå¹¶å¢å¼ºç»“æœï¼ˆç°åº¦å›¾+è¾¹ç¼˜ï¼‰
    enhanced = cv2.addWeighted(gray, 0.8, edges, 0.2, 0)

    # 6. è½¬æ¢å›BGRæ ¼å¼ï¼ˆä¿æŒé€šé“æ•°ä¸€è‡´ï¼‰
    return cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR)


# ================= æ¨¡å‹åˆå§‹åŒ– =================
def init_models(config):
    print("ğŸ”§ åˆå§‹åŒ–æ¨¡å‹ä¸­...")

    # YOLOv8
    yolo = YOLO(config.YOLO_WEIGHT)

    # ByteTrack
    tracker = BYTETracker(SimpleNamespace(
        track_thresh=0.5,
        track_buffer=50,
        match_thresh=0.7,
        min_box_area=100,
        mot20=False
    ))

    # è½¦ç‰Œè¯†åˆ«æ¨¡å‹
    lprnet = LPRNet(class_num=len(CHARS), dropout_rate=0.5)
    stn = STNet()
    lprnet.load_state_dict(torch.load(config.LPRNET_WEIGHT, map_location=config.DEVICE, weights_only=True))
    stn.load_state_dict(torch.load(config.STN_WEIGHT, map_location=config.DEVICE, weights_only=True))
    lprnet.to(config.DEVICE).eval()
    stn.to(config.DEVICE).eval()

    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼")
    return yolo, tracker, lprnet, stn


# ================= è½¦ç‰Œè¯†åˆ«å¢å¼º =================
def recognize_plate_enhanced(lprnet, stn, plate_img, device, config):
    """
    å¢å¼ºç‰ˆè½¦ç‰Œè¯†åˆ«ï¼šå¤šæ¬¡è¯†åˆ«+ç»“æœæŠ•ç¥¨+ç½®ä¿¡åº¦è¿‡æ»¤
    """
    if plate_img is None or plate_img.size == 0:
        return "", 0.0

    # é¢„å¤„ç†å¢å¼º
    processed = preprocess_plate_image(plate_img)
    if processed is None:
        return "", 0.0

    # å¤šæ¬¡è¯†åˆ«å–ç¨³å®šç»“æœ
    results = []
    for _ in range(config.PLATE_RECOG_REPEAT):
        # å°ºå¯¸æ ‡å‡†åŒ–
        resized = cv2.resize(processed, (94, 24))
        img_tensor = torch.tensor(resized.transpose(2, 0, 1)).unsqueeze(0).float().to(device)

        # æ¨ç†
        with torch.no_grad():
            stn_out = stn(img_tensor)
            preds = lprnet(stn_out)

        # è§£ç å¹¶è®¡ç®—ç½®ä¿¡åº¦
        labels, confs = decode(preds.cpu().detach().numpy(), CHARS)
        if labels and len(labels[0]) >= 7:  # æ ‡å‡†è½¦ç‰Œé•¿åº¦æ ¡éªŒ
            results.append((labels[0], np.mean(confs[0])))

    if not results:
        return "", 0.0

    # è¿‡æ»¤ä½ç½®ä¿¡åº¦ç»“æœ
    filtered = [(l, c) for l, c in results if c >= config.PLATE_RECOG_THRESH]
    if not filtered:
        return "", 0.0

    # ç»“æœæŠ•ç¥¨ï¼ˆå–å‡ºç°æ¬¡æ•°æœ€å¤šçš„ç»“æœï¼‰
    label_counts = defaultdict(float)
    for label, conf in filtered:
        label_counts[label] += conf  # åŠ æƒè®¡æ•°ï¼ˆç½®ä¿¡åº¦é«˜çš„æƒé‡é«˜ï¼‰

    best_label = max(label_counts.items(), key=lambda x: x[1])[0]
    best_conf = max(c for l, c in filtered if l == best_label)

    return best_label, best_conf


# ================= è½¦ç‰Œè·Ÿè¸ªåŒ¹é…å¢å¼º =================
def match_plate_to_vehicle(plates, tracks, frame, lprnet, stn, device, config):
    """
    å¢å¼ºç‰ˆè½¦ç‰Œ-è½¦è¾†åŒ¹é…ï¼šåŸºäºä½ç½®çº¦æŸ+å†å²åŒ¹é…+IOUåŠ æƒ
    """
    id2plate = {}
    valid_plates = []

    # 1. è¿‡æ»¤æ— æ•ˆè½¦ç‰Œï¼ˆé¢ç§¯ã€å®½é«˜æ¯”æ ¡éªŒï¼‰
    for bbox in plates:
        x1, y1, x2, y2, score = bbox[:5]
        if score < config.PLATE_MIN_CONF:
            continue

        # è®¡ç®—å®½é«˜æ¯”å’Œé¢ç§¯
        w, h = x2 - x1, y2 - y1
        area = w * h
        aspect_ratio = w / h if h > 0 else 0

        # è¿‡æ»¤ä¸ç¬¦åˆæ ‡å‡†çš„è½¦ç‰Œ
        if (area < config.PLATE_MIN_AREA or
                not (config.PLATE_ASPECT_RATIO[0] <= aspect_ratio <= config.PLATE_ASPECT_RATIO[1])):
            continue

        valid_plates.append((x1, y1, x2, y2, score))

    # 2. è¯†åˆ«æœ‰æ•ˆè½¦ç‰Œå¹¶åŒ¹é…
    for (x1, y1, x2, y2, score) in valid_plates:
        # æˆªå–è½¦ç‰ŒåŒºåŸŸ
        plate_crop = frame[int(y1):int(y2), int(x1):int(x2)]
        plate_text, conf = recognize_plate_enhanced(lprnet, stn, plate_crop, device, config)

        if not plate_text or conf < config.PLATE_RECOG_THRESH:
            continue

        # 3. æ™ºèƒ½åŒ¹é…åˆ°è½¦è¾†è·Ÿè¸ªæ¡†
        best_match = None
        max_score = 0

        for track in tracks:
            tx1, ty1, tx2, ty2 = track.tlbr
            track_id = track.track_id

            # è®¡ç®—IOU
            ix1 = max(x1, tx1)
            iy1 = max(y1, ty1)
            ix2 = min(x2, tx2)
            iy2 = min(y2, ty2)
            iw = max(0, ix2 - ix1)
            ih = max(0, iy2 - iy1)
            inter = iw * ih
            union = (x2 - x1) * (y2 - y1) + (tx2 - tx1) * (ty2 - ty1) - inter
            iou = inter / union if union > 0 else 0

            # åŠ æƒè¯„åˆ†ï¼ˆIOU + ä½ç½®çº¦æŸï¼šè½¦ç‰Œé€šå¸¸åœ¨è½¦è¾†ä¸‹éƒ¨ï¼‰
            position_score = 1.0 if (ty1 <= y1 <= ty2 and y2 <= ty2) else 0.5
            total_score = iou * 0.7 + position_score * 0.3

            if total_score > max_score and total_score > 0.4:
                max_score = total_score
                best_match = track_id

        if best_match is not None:
            id2plate[best_match] = (plate_text, conf)

    return id2plate


# ================= å·¥å…·å‡½æ•° =================
def convert_pixel_speed_to_kmh(pixel_speed, pixel_per_meter, frame_rate):
    meter_per_second = (pixel_speed / pixel_per_meter) * frame_rate
    return max(0, round(meter_per_second * 3.6, 1))


def smooth_speed(speeds, window_size):
    if len(speeds) < window_size:
        window_size = len(speeds)
    return sum(speeds[-window_size:]) / window_size if window_size > 0 else 0


def cv2_add_text(img, text, pos, color=(0, 255, 255), size=12):
    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    try:
        font = ImageFont.truetype("C:/Windows/Fonts/simsun.ttc", size)
    except:
        font = ImageFont.load_default()
    draw.text(pos, text, color, font=font)
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)


# ================= ä¸»å‡½æ•° =================
def main():
    config = Config()
    yolo, tracker, lprnet, stn = init_models(config)

    cap = cv2.VideoCapture(config.VIDEO_PATH)
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘: {config.VIDEO_PATH}")
        return

    # è·Ÿè¸ªçŠ¶æ€å­˜å‚¨
    track_pts = defaultdict(lambda: deque(maxlen=30))  # è½¨è¿¹
    track_speeds = defaultdict(list)  # é€Ÿåº¦å†å²
    track_plates = defaultdict(lambda: deque(maxlen=config.PLATE_HISTORY_LEN))  # è½¦ç‰Œå†å²
    frame_id = 0

    print("ğŸš€ å¼€å§‹å¤„ç† (æŒ‰ESCé€€å‡º)")
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        frame_id += 1
        frame_copy = frame.copy()

        # 1. è½¦è¾†æ£€æµ‹
        dets = yolo(frame, device=config.DEVICE, conf=0.5, classes=[2, 3, 5, 7], verbose=False)[0]
        vehicle_dets = [[*box[:4], box[4]] for box in dets.boxes.data.cpu().numpy()]

        # 2. ç›®æ ‡è·Ÿè¸ª
        tracks = tracker.update(np.array(vehicle_dets, dtype=np.float32),
                                frame.shape[:2], frame.shape[:2])

        # 3. è½¦ç‰Œæ£€æµ‹ä¸åŒ¹é…ï¼ˆæ¯3å¸§ä¸€æ¬¡ï¼Œå¹³è¡¡æ€§èƒ½ï¼‰
        if frame_id % 3 == 0:
            plates = create_mtcnn_net(
                frame, mini_lp_size=(50, 15), device=config.DEVICE,
                p_model_path=config.MTCNN_PNET, o_model_path=config.MTCNN_ONET
            )
            plate_matches = match_plate_to_vehicle(plates, tracks, frame, lprnet, stn, config.DEVICE, config)

            # æ›´æ–°è½¦ç‰Œå†å²ï¼ˆç”¨äºç¨³å®šç»“æœï¼‰
            for track_id, (plate, conf) in plate_matches.items():
                track_plates[track_id].append((plate, conf))

        # 4. ç»˜åˆ¶ç»“æœ
        for track in tracks:
            tx1, ty1, tx2, ty2 = track.tlbr
            track_id = track.track_id
            center = ((tx1 + tx2) / 2, (ty1 + ty2) / 2)
            track_pts[track_id].append(center)

            # è®¡ç®—é€Ÿåº¦
            speed = 0.0
            if len(track_pts[track_id]) >= 2:
                px, py = track_pts[track_id][-2]
                dx, dy = center[0] - px, center[1] - py
                pixel_dist = math.hypot(dx, dy)
                track_speeds[track_id].append(pixel_dist)
                speed = convert_pixel_speed_to_kmh(
                    smooth_speed(track_speeds[track_id], config.SPEED_SMOOTH_WINDOW),
                    config.PIXEL_PER_METER, config.FRAME_RATE
                )

            # ç¡®å®šæœ€ç»ˆè½¦ç‰Œï¼ˆä»å†å²ä¸­é€‰ç½®ä¿¡åº¦æœ€é«˜çš„ï¼‰
            final_plate = "æœªçŸ¥"
            if track_plates[track_id]:
                best_plate = max(track_plates[track_id], key=lambda x: x[1])
                final_plate = best_plate[0]

            # ç»˜åˆ¶è·Ÿè¸ªæ¡†å’Œä¿¡æ¯
            cv2.rectangle(frame_copy, (int(tx1), int(ty1)), (int(tx2), int(ty2)), (255, 0, 0), 2)
            info = f"ID:{track_id} è½¦ç‰Œ:{final_plate} é€Ÿåº¦:{speed}km/h"
            frame_copy = cv2_add_text(frame_copy, info, (int(tx1), max(10, int(ty1) - 30)))

            # ç»˜åˆ¶è½¨è¿¹
            for i in range(1, len(track_pts[track_id])):
                cv2.line(frame_copy,
                         (int(track_pts[track_id][i - 1][0]), int(track_pts[track_id][i - 1][1])),
                         (int(track_pts[track_id][i][0]), int(track_pts[track_id][i][1])),
                         (0, 255, 0), 2)

        cv2.imshow("å¢å¼ºç‰ˆæ™ºèƒ½äº¤é€šç›‘æ§", frame_copy)
        if cv2.waitKey(1) == 27:
            break

    cap.release()
    cv2.destroyAllWindows()

    print("ğŸ‘‹ å¤„ç†å®Œæˆ")


if __name__ == "__main__":
    main()